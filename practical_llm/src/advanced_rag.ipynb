{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bea1336-eaa4-4fe2-bf61-015ad86be5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    Document,\n",
    "    Settings,\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex\n",
    ")\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import pandas as pd\n",
    "from trulens_eval import Tru, TruLlama\n",
    "from utils import (\n",
    "    build_automerging_index,\n",
    "    build_sentence_window_index,\n",
    "    evaluate_engine,\n",
    "    get_automerging_query_engine,\n",
    "    get_feedback_func,\n",
    "    get_sentence_window_query_engine,\n",
    "    setup \n",
    ")\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44bebf19-d9de-4174-b52d-d93a55b6dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "setup() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab8f616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-11 14:43:29--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8000::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: â€˜../data/paul_graham_essay.txtâ€™\n",
      "\n",
      "../data/paul_graham 100%[===================>]  73.28K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2024-05-11 14:43:29 (4.62 MB/s) - â€˜../data/paul_graham_essay.txtâ€™ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p '../data'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O '../data/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61a8af43-0e69-4b32-8ff4-d931786b4c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"../data/paul_graham_essay.txt\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20d2d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, list)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents), type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10389b12-8dfb-4786-895e-017a5386df3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc47a00-b8d5-4fd2-a226-880cdaec7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1511bf5-6423-45b8-b267-9795f27da8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Paul Graham is known for his work in programming, particularly for his involvement in creating a new dialect of Lisp called Arc. He is also known for his essays, which he started publishing online and eventually compiled into a book titled \"Hackers & Painters.\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine.query(\"What is Paul Graham known for?\")\n",
    "str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c676bee2-718b-442b-b4c2-1c0e983257d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eb61a82-a13d-40ff-acd6-107d804171fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eval_questions.txt', 'r') as file:\n",
    "    eval_questions = file.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cd7eabd-68b4-4104-969a-55669eb6395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/charlescamp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "feedbacks = get_feedback_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d844e03-a180-4136-8410-0bb228aa56d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5583bab46de84155aa526ffbb8fea50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af87977dd4314543a3fca4e02d05647b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3411259e735423785f4f41c4cec39bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3ba2060aa64e12883699ede7c6be3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afecbdef01024512b068dc06f344ebb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a182df11eee94af2bc45135ffd681369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2da1f133aa475784f26b9c02ed3840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d7947df3c44b6b99273a42fe8ee18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f173f592d2e46db976a4de074cb1a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10f9a2daf8846fda38ec7ac953256ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a0d218f62d4b04939ba3c355d1e17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f4d0484ec44ed68c3cf80570ae6a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cf4e4b3ddb4297a0021b943740247f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a32b370c114ece9b95c1ed82559264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef571c7045f438fa7f1a3fef93e6b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b40a676be0b4f3395c540b30a14710a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0f1f22ed924981bac1203cda7a8176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30119513fff045e587709319ea33f4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TruLlama(tru_class_info=trulens_eval.tru_llama.TruLlama, app_id='Direct Query Engine', tags='-', metadata={}, feedback_definitions=[], feedback_mode=<FeedbackMode.WITH_APP_THREAD: 'with_app_thread'>, root_class=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, app=<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x319a9e930>, initial_app_loader_dump=None, app_extra_json={}, feedbacks=[FeedbackDefinition(Answer Relevance,\n",
       "\tselectors={'prompt': Lens().__record__.main_input, 'response': Lens().__record__.main_output},\n",
       "\tif_exists=None\n",
       "), FeedbackDefinition(Context Relevance,\n",
       "\tselectors={'prompt': Lens().__record__.main_input, 'response': Lens().__record__.app.query.rets.source_nodes[:].node.text},\n",
       "\tif_exists=None\n",
       "), FeedbackDefinition(Groundedness,\n",
       "\tselectors={'source': Lens().__record__.app.query.rets.source_nodes[:].node.text, 'statement': Lens().__record__.main_output},\n",
       "\tif_exists=None\n",
       ")], tru=<trulens_eval.tru.Tru object at 0x31ae8f3e0>, db=SQLAlchemyDB(redact_keys=False, table_prefix='trulens_', engine_params={'url': 'sqlite:///default.sqlite', 'pool_size': 10, 'pool_recycle': 300, 'pool_pre_ping': True, 'max_overflow': 2, 'pool_use_lifo': True}, session_params={}, engine=Engine(sqlite:///default.sqlite), session=sessionmaker(class_='Session', bind=Engine(sqlite:///default.sqlite), autoflush=True, expire_on_commit=True), orm=<class 'trulens_eval.database.orm.new_orm.<locals>.NewORM'>), instrument=<trulens_eval.tru_llama.LlamaInstrument object at 0x368defef0>, recording_contexts=<ContextVar name='recording_contexts' at 0x3091d3ec0>, instrumented_methods={13339912640: {<function BaseRetriever.retrieve at 0x179721580>: Lens().app._retriever, <function VectorIndexRetriever._retrieve at 0x3064b5d00>: Lens().app._retriever, <function VectorIndexRetriever._aretrieve at 0x3064b60c0>: Lens().app._retriever, <function BaseRetriever._retrieve at 0x179721a80>: Lens().app._retriever, <function BaseRetriever._aretrieve at 0x1797219e0>: Lens().app._retriever}, 4365922176: {<function llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict at 0x30778c7c0>: Lens().app._response_synthesizer._llm, <function llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict at 0x30778ca40>: Lens().app._response_synthesizer._llm, <function llm_completion_callback.<locals>.wrap.<locals>.wrapped_async_llm_predict at 0x30778dee0>: Lens().app._response_synthesizer._llm, <function llm_completion_callback.<locals>.wrap.<locals>.wrapped_async_llm_predict at 0x30778e160>: Lens().app._response_synthesizer._llm, <function llm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat at 0x30778c2c0>: Lens().app._response_synthesizer._llm, <function llm_chat_callback.<locals>.wrap.<locals>.wrapped_async_llm_chat at 0x30778d9e0>: Lens().app._response_synthesizer._llm, <function llm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat at 0x30778c540>: Lens().app._response_synthesizer._llm, <function BaseLLM.complete at 0x12fd3c860>: Lens().app._response_synthesizer._llm, <function BaseLLM.stream_complete at 0x12fd3ca40>: Lens().app._response_synthesizer._llm, <function BaseLLM.acomplete at 0x12fd3cb80>: Lens().app._response_synthesizer._llm, <function BaseLLM.astream_complete at 0x12fd3ccc0>: Lens().app._response_synthesizer._llm, <function BaseLLM.chat at 0x12fd3c900>: Lens().app._response_synthesizer._llm, <function BaseLLM.achat at 0x12fd3cae0>: Lens().app._response_synthesizer._llm, <function BaseLLM.stream_chat at 0x12fd3c9a0>: Lens().app._response_synthesizer._llm}, 13319208736: {<function CompactAndRefine.get_response at 0x17a0cfb00>: Lens().app._response_synthesizer, <function Refine.get_response at 0x17a0cf9c0>: Lens().app._response_synthesizer, <function BaseSynthesizer.get_response at 0x17a0cd3a0>: Lens().app._response_synthesizer}, 13315467568: {<function BaseQueryEngine.query at 0x12fd84ea0>: Lens().app, <function BaseQueryEngine.aquery at 0x12fd854e0>: Lens().app, <function RetrieverQueryEngine.retrieve at 0x30ca34680>: Lens().app, <function RetrieverQueryEngine.synthesize at 0x30ca34860>: Lens().app, <function BaseQueryEngine.retrieve at 0x12fd85620>: Lens().app, <function BaseQueryEngine.synthesize at 0x12fd85580>: Lens().app}}, records_with_pending_feedback_results=<queue.Queue object at 0x368defd40>, manage_pending_feedback_results_thread=<Thread(Thread-7 (_future_target_wrapper), started daemon 14920216576)>, selector_check_warning=False, selector_nocheck=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_engine(\n",
    "    query_engine=query_engine,\n",
    "    feedbacks=feedbacks,\n",
    "    app_id=\"Direct Query Engine\",\n",
    "    eval_questions=eval_questions,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3dafdd8-3adc-4a24-a38f-5f41ab7d11ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e5d7bb49854a5998b60a7f52674751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d55931bd-79df-4b67-83ff-023612237ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Answer Relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"What were Paul Graham's two main areas of focus before college?\"</td>\n",
       "      <td>\"Writing and programming\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"What programming language did Paul Graham use in 9th grade on the IBM 1401?\"</td>\n",
       "      <td>\"Paul Graham used an early version of Fortran as the programming language in 9th grade on the IBM 1401.\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"How did Paul Graham's experience with microcomputers change his approach to programming?\"</td>\n",
       "      <td>\"Paul Graham's experience with microcomputers changed his approach to programming by allowing him to have a computer right in front of him that could respond to his keystrokes in real-time, as opposed to the previous method of using punch cards. This direct interaction with the computer enabled him to type programs directly into the machine, which was a significant departure from the punch card system he had previously used.\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"What was Paul Graham's initial plan for his college major?\"</td>\n",
       "      <td>\"Paul Graham's initial plan for his college major was to study philosophy.\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"What inspired Paul Graham to pursue AI?\"</td>\n",
       "      <td>\"The novel \\\"The Moon is a Harsh Mistress\\\" by Heinlein, featuring an intelligent computer called Mike, and a PBS documentary showing Terry Winograd using SHRDLU were the inspirations that led Paul Graham to pursue AI.\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Why did Paul Graham start teaching himself Lisp?\"</td>\n",
       "      <td>\"Paul Graham started teaching himself Lisp because he found it interesting for its own sake, not just for its association with AI, even though that was the main reason people cared about it at the time.\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"What led Paul Graham to realize that AI, as practiced at the time, was flawed?\"</td>\n",
       "      <td>\"Paul Graham realized that AI, as practiced at the time, was flawed when he observed that the programs in AI were only able to handle a very proper subset of natural language as a formal language. He understood that there was a significant gap between what these programs could do and actually understanding natural language. This realization led him to conclude that the approach of using explicit data structures to represent concepts in AI was not effective and was not going to lead to true intelligence.\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"How did Paul Graham's experience at the Accademia di Belli Arti differ from his expectations?\"</td>\n",
       "      <td>\"Paul Graham's experience at the Accademia di Belli Arti differed from his expectations in that he was able to see Florence at street level in various conditions, from empty dark winter evenings to sweltering summer days with crowded streets, which provided him with a more diverse and vivid perspective of the city than he had anticipated.\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"What prompted Paul Graham to leave RISD in 1993?\"</td>\n",
       "      <td>\"Paul Graham left RISD in 1993 due to feeling dissatisfied with the teaching and learning dynamics at the art school.\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"What was the catalyst for Paul Graham's involvement in the World Wide Web and the founding of Viaweb?\"</td>\n",
       "      <td>\"The catalyst for Paul Graham's involvement in the World Wide Web and the founding of Viaweb was his realization of the potential of the web as a platform for business opportunities. He recognized the impact that graphical user interfaces had on microcomputers and believed that the web could have a similar effect on the internet. This led him to start a company to put art galleries online, which eventually evolved into the idea of building online stores. The concept of web apps and the ability to run software on servers without the need for client software further fueled his interest and led to the founding of Viaweb.\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                     input  \\\n",
       "0                                        \"What were Paul Graham's two main areas of focus before college?\"   \n",
       "1                            \"What programming language did Paul Graham use in 9th grade on the IBM 1401?\"   \n",
       "2               \"How did Paul Graham's experience with microcomputers change his approach to programming?\"   \n",
       "3                                             \"What was Paul Graham's initial plan for his college major?\"   \n",
       "4                                                                \"What inspired Paul Graham to pursue AI?\"   \n",
       "5                                                       \"Why did Paul Graham start teaching himself Lisp?\"   \n",
       "6                         \"What led Paul Graham to realize that AI, as practiced at the time, was flawed?\"   \n",
       "7          \"How did Paul Graham's experience at the Accademia di Belli Arti differ from his expectations?\"   \n",
       "8                                                       \"What prompted Paul Graham to leave RISD in 1993?\"   \n",
       "9  \"What was the catalyst for Paul Graham's involvement in the World Wide Web and the founding of Viaweb?\"   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               output  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \"Writing and programming\"   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \"Paul Graham used an early version of Fortran as the programming language in 9th grade on the IBM 1401.\"   \n",
       "2                                                                                                                                                                                                       \"Paul Graham's experience with microcomputers changed his approach to programming by allowing him to have a computer right in front of him that could respond to his keystrokes in real-time, as opposed to the previous method of using punch cards. This direct interaction with the computer enabled him to type programs directly into the machine, which was a significant departure from the punch card system he had previously used.\"   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \"Paul Graham's initial plan for his college major was to study philosophy.\"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                         \"The novel \\\"The Moon is a Harsh Mistress\\\" by Heinlein, featuring an intelligent computer called Mike, and a PBS documentary showing Terry Winograd using SHRDLU were the inspirations that led Paul Graham to pursue AI.\"   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                         \"Paul Graham started teaching himself Lisp because he found it interesting for its own sake, not just for its association with AI, even though that was the main reason people cared about it at the time.\"   \n",
       "6                                                                                                                       \"Paul Graham realized that AI, as practiced at the time, was flawed when he observed that the programs in AI were only able to handle a very proper subset of natural language as a formal language. He understood that there was a significant gap between what these programs could do and actually understanding natural language. This realization led him to conclude that the approach of using explicit data structures to represent concepts in AI was not effective and was not going to lead to true intelligence.\"   \n",
       "7                                                                                                                                                                                                                                                                                               \"Paul Graham's experience at the Accademia di Belli Arti differed from his expectations in that he was able to see Florence at street level in various conditions, from empty dark winter evenings to sweltering summer days with crowded streets, which provided him with a more diverse and vivid perspective of the city than he had anticipated.\"   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \"Paul Graham left RISD in 1993 due to feeling dissatisfied with the teaching and learning dynamics at the art school.\"   \n",
       "9  \"The catalyst for Paul Graham's involvement in the World Wide Web and the founding of Viaweb was his realization of the potential of the web as a platform for business opportunities. He recognized the impact that graphical user interfaces had on microcomputers and believed that the web could have a similar effect on the internet. This led him to start a company to put art galleries online, which eventually evolved into the idea of building online stores. The concept of web apps and the ability to run software on servers without the need for client software further fueled his interest and led to the founding of Viaweb.\"   \n",
       "\n",
       "   Groundedness  Context Relevance  Answer Relevance  \n",
       "0           1.0                0.6               1.0  \n",
       "1           1.0                0.9               1.0  \n",
       "2           0.0                0.9               1.0  \n",
       "3           1.0                0.8               1.0  \n",
       "4           1.0                0.6               1.0  \n",
       "5           1.0                0.1               0.9  \n",
       "6           NaN                0.6               0.9  \n",
       "7           NaN                0.2               0.8  \n",
       "8           0.0                NaN               0.8  \n",
       "9           NaN                NaN               NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[[\"input\", \"output\"] + feedback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04bead30-2b0e-4d5f-b7c9-ab53cf514d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_index = build_sentence_window_index(documents, Settings.llm)\n",
    "window_engine = get_sentence_window_query_engine(window_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5981359-f86a-441b-9195-6da3147d5efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0494897fefc642329f86d53018f06841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e23a941df844c10a6b8806f2f656674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bbb264b6064685a8a4ebe1da486fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5a6daca8ac4738b315aefd0f266a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ad0379f5cb4fa1bfa581d41853d5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcae512d13d49bcb5108de0aa6272b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b1fa702885480f84c8e78bd4750104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72db4c73be4847eba2925b3310070d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ff6ed6135f4b3d9b4286c5bee50cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94e4846dacf4c8ba7eab4c0a679f5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TruLlama(tru_class_info=trulens_eval.tru_llama.TruLlama, app_id='Window Engine', tags='-', metadata={}, feedback_definitions=[], feedback_mode=<FeedbackMode.WITH_APP_THREAD: 'with_app_thread'>, root_class=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, app=<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x38efacce0>, initial_app_loader_dump=None, app_extra_json={}, feedbacks=[FeedbackDefinition(Answer Relevance,\n",
       "\tselectors={'prompt': Lens().__record__.main_input, 'response': Lens().__record__.main_output},\n",
       "\tif_exists=None\n",
       "), FeedbackDefinition(Context Relevance,\n",
       "\tselectors={'prompt': Lens().__record__.main_input, 'response': Lens().__record__.app.query.rets.source_nodes[:].node.text},\n",
       "\tif_exists=None\n",
       "), FeedbackDefinition(Groundedness,\n",
       "\tselectors={'source': Lens().__record__.app.query.rets.source_nodes[:].node.text, 'statement': Lens().__record__.main_output},\n",
       "\tif_exists=None\n",
       ")], tru=<trulens_eval.tru.Tru object at 0x31ae8f3e0>, db=SQLAlchemyDB(redact_keys=False, table_prefix='trulens_', engine_params={'url': 'sqlite:///default.sqlite', 'pool_size': 10, 'pool_recycle': 300, 'pool_pre_ping': True, 'max_overflow': 2, 'pool_use_lifo': True}, session_params={}, engine=Engine(sqlite:///default.sqlite), session=sessionmaker(class_='Session', bind=Engine(sqlite:///default.sqlite), autoflush=True, expire_on_commit=True), orm=<class 'trulens_eval.database.orm.new_orm.<locals>.NewORM'>), instrument=<trulens_eval.tru_llama.LlamaInstrument object at 0x3c9ac1b80>, recording_contexts=<ContextVar name='recording_contexts' at 0x392ca4b30>, instrumented_methods={15220160320: {<function BaseRetriever.retrieve at 0x179721580>: Lens().app._retriever, <function VectorIndexRetriever._retrieve at 0x3064b5d00>: Lens().app._retriever, <function VectorIndexRetriever._aretrieve at 0x3064b60c0>: Lens().app._retriever, <function BaseRetriever._retrieve at 0x179721a80>: Lens().app._retriever, <function BaseRetriever._aretrieve at 0x1797219e0>: Lens().app._retriever}, 4365922176: {<function llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict at 0x30778c7c0>: Lens().app._response_synthesizer._llm, <function llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict at 0x30778ca40>: Lens().app._response_synthesizer._llm, <function llm_completion_callback.<locals>.wrap.<locals>.wrapped_async_llm_predict at 0x30778dee0>: Lens().app._response_synthesizer._llm, <function llm_completion_callback.<locals>.wrap.<locals>.wrapped_async_llm_predict at 0x30778e160>: Lens().app._response_synthesizer._llm, <function llm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat at 0x30778c2c0>: Lens().app._response_synthesizer._llm, <function llm_chat_callback.<locals>.wrap.<locals>.wrapped_async_llm_chat at 0x30778d9e0>: Lens().app._response_synthesizer._llm, <function llm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat at 0x30778c540>: Lens().app._response_synthesizer._llm, <function BaseLLM.complete at 0x12fd3c860>: Lens().app._response_synthesizer._llm, <function BaseLLM.stream_complete at 0x12fd3ca40>: Lens().app._response_synthesizer._llm, <function BaseLLM.acomplete at 0x12fd3cb80>: Lens().app._response_synthesizer._llm, <function BaseLLM.astream_complete at 0x12fd3ccc0>: Lens().app._response_synthesizer._llm, <function BaseLLM.chat at 0x12fd3c900>: Lens().app._response_synthesizer._llm, <function BaseLLM.achat at 0x12fd3cae0>: Lens().app._response_synthesizer._llm, <function BaseLLM.stream_chat at 0x12fd3c9a0>: Lens().app._response_synthesizer._llm}, 14923699344: {<function CompactAndRefine.get_response at 0x17a0cfb00>: Lens().app._response_synthesizer, <function Refine.get_response at 0x17a0cf9c0>: Lens().app._response_synthesizer, <function BaseSynthesizer.get_response at 0x17a0cd3a0>: Lens().app._response_synthesizer}, 15283703008: {<function BaseQueryEngine.query at 0x12fd84ea0>: Lens().app, <function BaseQueryEngine.aquery at 0x12fd854e0>: Lens().app, <function RetrieverQueryEngine.retrieve at 0x30ca34680>: Lens().app, <function RetrieverQueryEngine.synthesize at 0x30ca34860>: Lens().app, <function BaseQueryEngine.retrieve at 0x12fd85620>: Lens().app, <function BaseQueryEngine.synthesize at 0x12fd85580>: Lens().app}, 14901462544: {<function MetadataReplacementPostProcessor._postprocess_nodes at 0x17a0f2de0>: Lens().app._node_postprocessors[0], <function BaseNodePostprocessor._postprocess_nodes at 0x17a0f2020>: Lens().app._node_postprocessors[0]}, 15312334224: {<function SentenceTransformerRerank._postprocess_nodes at 0x17a12f060>: Lens().app._node_postprocessors[1], <function BaseNodePostprocessor._postprocess_nodes at 0x17a0f2020>: Lens().app._node_postprocessors[1]}}, records_with_pending_feedback_results=<queue.Queue object at 0x3c9ac2060>, manage_pending_feedback_results_thread=<Thread(Thread-8 (_future_target_wrapper), started daemon 16527650816)>, selector_check_warning=False, selector_nocheck=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_engine(\n",
    "    query_engine=window_engine,\n",
    "    feedbacks=feedbacks,\n",
    "    app_id=\"Window Engine\",\n",
    "    eval_questions=eval_questions,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38235318-3143-4e83-8695-d5193cde6565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394479a407ce426c939c5fc03ee27616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merging_index = build_automerging_index(documents, Settings.llm, chunk_sizes=[1024, 256, 64])\n",
    "merging_engine = get_automerging_query_engine(merging_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c4cda28-f355-46b4-a8d3-1ed2994fca33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 91152afa-a396-4cda-b246-122829b9f388.\n",
      "> Parent node text: Always seem patient, as if you know that everything wil l come to you eventually.  Become a \n",
      "dete...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412dcc798dd04eb187590de00a04b342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: f3c07834-955f-4e9f-83f1-fb397df9916e.\n",
      "> Parent node text: You can die from someone elseâ€™s misery â€“ emotional sta tes are as infectious as disease.  You \n",
      "ma...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 86cae63a-5ca0-4279-b238-aa2c78341bc0.\n",
      "> Parent node text: They are wolves in lambsâ€™ clothing.  Choose your \n",
      "victims and opponents carefully, then â€“ never o...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 2bbaefa9-ed84-4bef-bfa8-04f41831ee16.\n",
      "> Parent node text: You can die from someone elseâ€™s misery â€“ emotional sta tes are as infectious as disease.  You \n",
      "ma...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d9f06199964f709bede3a0f6330f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add7773c7356438592d5c13559cbd217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ceeb77d3bd44c5a89dc586b1d51846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 91152afa-a396-4cda-b246-122829b9f388.\n",
      "> Parent node text: Always seem patient, as if you know that everything wil l come to you eventually.  Become a \n",
      "dete...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3ac7fd34ea476a8de03a412ecfdc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678988eac13343418f8a21b02e96a57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dc84f64b15480ba4b79362e5438f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe64f0630b7643baa4c5b700d28a8a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 4 nodes into parent node.\n",
      "> Parent node id: 0b1be9dd-e5fa-43f0-9f3c-1dd6bacae030.\n",
      "> Parent node text: rather than letting others define if for you.  Incorpora te dramatic devices into your public \n",
      "ge...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 91152afa-a396-4cda-b246-122829b9f388.\n",
      "> Parent node text: Always seem patient, as if you know that everything wil l come to you eventually.  Become a \n",
      "dete...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 90c41ad9-37a1-4c23-9640-14768c414c00.\n",
      "> Parent node text: rather than letting others define if for you.  Incorpora te dramatic devices into your public \n",
      "ge...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675a3672a8da42778ef8ad9d2c87ec5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f69e866f8749deb8bcafe9bbaac911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7ae80be43f4929907ea3cecbeca13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7b066559fd4caa905cdb500c0db76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 91152afa-a396-4cda-b246-122829b9f388.\n",
      "> Parent node text: Always seem patient, as if you know that everything wil l come to you eventually.  Become a \n",
      "dete...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cd4eef28a94f09b4f174357c76ad0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5df6cacfbb6413593a3732f4c66e014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49428841d954e2bbdff8aec0228ee4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038f422a372b4a87b84416ab96052e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cc98bb5f8b4e08b635fb0ca24f77ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9f71494fbe464d9aeb7fe2001fa2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: bac6e040-320c-47b8-80a3-77ca28fae7d1.\n",
      "> Parent node text: Law 45  \n",
      "Preach the Need for Change, but Never Reform too much at O nce  \n",
      "Everyone understands th...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 91152afa-a396-4cda-b246-122829b9f388.\n",
      "> Parent node text: Always seem patient, as if you know that everything wil l come to you eventually.  Become a \n",
      "dete...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: fa14efa5-f52e-4651-80cb-c692b6fc6fe5.\n",
      "> Parent node text: Law 45  \n",
      "Preach the Need for Change, but Never Reform too much at O nce  \n",
      "Everyone understands th...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8587e3dd5c1c4615a7c390a715eec2db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d489c1d9094b94ac28d8e61d9e38df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 91152afa-a396-4cda-b246-122829b9f388.\n",
      "> Parent node text: Always seem patient, as if you know that everything wil l come to you eventually.  Become a \n",
      "dete...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4228a40d03b4bd486649f4cd45de7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 91152afa-a396-4cda-b246-122829b9f388.\n",
      "> Parent node text: Always seem patient, as if you know that everything wil l come to you eventually.  Become a \n",
      "dete...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19dcf24f68ca4eab838da4505dd61c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: 680f84de-2976-43e8-8668-0e52451a4e49.\n",
      "> Parent node text: What is offered for free is dangerous â€“ it usually involv es either a trick or a hidden obligatio...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 86cae63a-5ca0-4279-b238-aa2c78341bc0.\n",
      "> Parent node text: They are wolves in lambsâ€™ clothing.  Choose your \n",
      "victims and opponents carefully, then â€“ never o...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7834b4be7114cc089a2e30368487836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TruLlama(tru_class_info=trulens_eval.tru_llama.TruLlama, app_id='Merging Engine', tags='-', metadata={}, feedback_definitions=[], feedback_mode=<FeedbackMode.WITH_APP_THREAD: 'with_app_thread'>, root_class=llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine, app=<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x38e34afc0>, initial_app_loader_dump=None, app_extra_json={}, feedbacks=[FeedbackDefinition(Answer Relevance,\n",
       "\tselectors={'prompt': Lens().__record__.main_input, 'response': Lens().__record__.main_output},\n",
       "\tif_exists=None\n",
       "), FeedbackDefinition(Context Relevance,\n",
       "\tselectors={'prompt': Lens().__record__.main_input, 'response': Lens().__record__.app.query.rets.source_nodes[:].node.text},\n",
       "\tif_exists=None\n",
       "), FeedbackDefinition(Groundedness,\n",
       "\tselectors={'source': Lens().__record__.app.query.rets.source_nodes[:].node.text, 'statement': Lens().__record__.main_output},\n",
       "\tif_exists=None\n",
       ")], tru=<trulens_eval.tru.Tru object at 0x31ae8f3e0>, db=SQLAlchemyDB(redact_keys=False, table_prefix='trulens_', engine_params={'url': 'sqlite:///default.sqlite', 'pool_size': 10, 'pool_recycle': 300, 'pool_pre_ping': True, 'max_overflow': 2, 'pool_use_lifo': True}, session_params={}, engine=Engine(sqlite:///default.sqlite), session=sessionmaker(class_='Session', bind=Engine(sqlite:///default.sqlite), autoflush=True, expire_on_commit=True), orm=<class 'trulens_eval.database.orm.new_orm.<locals>.NewORM'>), instrument=<trulens_eval.tru_llama.LlamaInstrument object at 0x3dae70aa0>, recording_contexts=<ContextVar name='recording_contexts' at 0x3a6066160>, instrumented_methods={15978651936: {<function BaseRetriever.retrieve at 0x179721580>: Lens().app._retriever._vector_retriever, <function VectorIndexRetriever._retrieve at 0x3064b5d00>: Lens().app._retriever._vector_retriever, <function VectorIndexRetriever._aretrieve at 0x3064b60c0>: Lens().app._retriever._vector_retriever, <function BaseRetriever._retrieve at 0x179721a80>: Lens().app._retriever._vector_retriever, <function BaseRetriever._aretrieve at 0x1797219e0>: Lens().app._retriever._vector_retriever}, 15311969632: {<function BaseRetriever.retrieve at 0x179721580>: Lens().app._retriever, <function AutoMergingRetriever._retrieve at 0x30a8bb100>: Lens().app._retriever, <function BaseRetriever._aretrieve at 0x1797219e0>: Lens().app._retriever, <function BaseRetriever._retrieve at 0x179721a80>: Lens().app._retriever}, 4365922176: {<function llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict at 0x30778c7c0>: Lens().app._response_synthesizer._llm, <function llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict at 0x30778ca40>: Lens().app._response_synthesizer._llm, <function llm_completion_callback.<locals>.wrap.<locals>.wrapped_async_llm_predict at 0x30778dee0>: Lens().app._response_synthesizer._llm, <function llm_completion_callback.<locals>.wrap.<locals>.wrapped_async_llm_predict at 0x30778e160>: Lens().app._response_synthesizer._llm, <function llm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat at 0x30778c2c0>: Lens().app._response_synthesizer._llm, <function llm_chat_callback.<locals>.wrap.<locals>.wrapped_async_llm_chat at 0x30778d9e0>: Lens().app._response_synthesizer._llm, <function llm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat at 0x30778c540>: Lens().app._response_synthesizer._llm, <function BaseLLM.complete at 0x12fd3c860>: Lens().app._response_synthesizer._llm, <function BaseLLM.stream_complete at 0x12fd3ca40>: Lens().app._response_synthesizer._llm, <function BaseLLM.acomplete at 0x12fd3cb80>: Lens().app._response_synthesizer._llm, <function BaseLLM.astream_complete at 0x12fd3ccc0>: Lens().app._response_synthesizer._llm, <function BaseLLM.chat at 0x12fd3c900>: Lens().app._response_synthesizer._llm, <function BaseLLM.achat at 0x12fd3cae0>: Lens().app._response_synthesizer._llm, <function BaseLLM.stream_chat at 0x12fd3c9a0>: Lens().app._response_synthesizer._llm}, 15220154992: {<function CompactAndRefine.get_response at 0x17a0cfb00>: Lens().app._response_synthesizer, <function Refine.get_response at 0x17a0cf9c0>: Lens().app._response_synthesizer, <function BaseSynthesizer.get_response at 0x17a0cd3a0>: Lens().app._response_synthesizer}, 15270719424: {<function BaseQueryEngine.query at 0x12fd84ea0>: Lens().app, <function BaseQueryEngine.aquery at 0x12fd854e0>: Lens().app, <function RetrieverQueryEngine.retrieve at 0x30ca34680>: Lens().app, <function RetrieverQueryEngine.synthesize at 0x30ca34860>: Lens().app, <function BaseQueryEngine.retrieve at 0x12fd85620>: Lens().app, <function BaseQueryEngine.synthesize at 0x12fd85580>: Lens().app}, 16090284496: {<function SentenceTransformerRerank._postprocess_nodes at 0x17a12f060>: Lens().app._node_postprocessors[0], <function BaseNodePostprocessor._postprocess_nodes at 0x17a0f2020>: Lens().app._node_postprocessors[0]}}, records_with_pending_feedback_results=<queue.Queue object at 0x3ac309a00>, manage_pending_feedback_results_thread=<Thread(Thread-9 (_future_target_wrapper), started daemon 16544477184)>, selector_check_warning=False, selector_nocheck=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_engine(\n",
    "    query_engine=merging_engine,\n",
    "    feedbacks=feedbacks,\n",
    "    app_id=\"Merging Engine\",\n",
    "    eval_questions=eval_questions,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b7e4e5b-a044-40f0-8403-3b401058b283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5430c3fb2dc1427695dbf915642371a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0682ef6785846d5ac8b20718967ea51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.1.29:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "tru.get_leaderboard(app_ids=[])\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3648c8-2f45-4446-a00a-cdcb99b9263a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
